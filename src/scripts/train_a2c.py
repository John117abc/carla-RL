"""
æ•°æ®é‡‡é›†ä¸ç¯å¢ƒæµ‹è¯•è„šæœ¬ã€‚
ç”¨äºéªŒè¯ CarlaEnv æ˜¯å¦èƒ½æ­£å¸¸ reset/stepï¼Œå¹¶æ‰“å°è§‚æµ‹ã€åŠ¨ä½œã€å¥–åŠ±ç­‰ä¿¡æ¯ã€‚
å¯é€‰ä¿å­˜å›¾åƒæˆ–çŠ¶æ€æ—¥å¿—ã€‚
"""

import os
import torch
import numpy as np
import cv2
import sys
from src.utils import (load_config,get_logger,
                       setup_code_environment,
                       load_checkpoint)
from src.agents import A2CAgent

# === æ·»åŠ é¡¹ç›®æºç è·¯å¾„ ===
# sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

import gymnasium as gym
from src.envs.carla_env import CarlaEnv  # å‡è®¾ä½ çš„ç¯å¢ƒç±»åœ¨è¿™é‡Œ

logger = get_logger()


def save_image(obs, step: int, save_dir: str = "debug_images"):
    """ä¿å­˜è§‚æµ‹ä¸­çš„å›¾åƒï¼ˆå‡è®¾ obs æ˜¯ dict ä¸”åŒ…å« 'image'ï¼‰"""
    os.makedirs(save_dir, exist_ok=True)
    if isinstance(obs, dict) and 'image' in obs:
        img = obs['image']
        # å¦‚æœæ˜¯ (C, H, W)ï¼Œè½¬ä¸º (H, W, C)
        if img.shape[0] == 3:
            img = np.transpose(img, (1, 2, 0))
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(f"{save_dir}/step_{step:04d}.png", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
    elif isinstance(obs, np.ndarray) and obs.ndim == 3:
        img = (obs * 255).astype(np.uint8)
        if img.shape[0] == 3:
            img = np.transpose(img, (1, 2, 0))
        cv2.imwrite(f"{save_dir}/step_{step:04d}.png", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))


def main():
    logger.info('å¼€å§‹è¯»å–é…ç½®æ–‡ä»¶...')
    carla_config = load_config('configs/carla.yaml')
    env_config = load_config('configs/env.yaml')
    sys_config = load_config('configs/sys.yaml')
    rl_config = load_config('configs/rl.yaml')
    train_config = rl_config['rl']
    device = setup_code_environment(sys_config)
    history = []
    try:
        logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ– CARLA ç¯å¢ƒ...")
        env = CarlaEnv(
            render_mode=None,
            carla_config=carla_config,
            env_config=env_config
        )
        agent = A2CAgent(env=env, rl_config=rl_config, device=device)
        if train_config['continue_a2c']:
            logger.info("å¼€å§‹è¯»å–æ™ºèƒ½ä½“å‚æ•°...")
            agent.load(train_config["model_path_a2c"])

        logger.info("âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸï¼")
        logger.info(f"è§‚æµ‹ç©ºé—´: {env.observation_space}")
        logger.info(f"åŠ¨ä½œç©ºé—´: {env.action_space}")

        num_episodes = train_config["num_episodes"]
        global_step = 0
        episode = 0
        while episode < num_episodes:
            logger.info(f"\nâ–¶ï¸  å¼€å§‹ç¬¬ {episode + 1} è½®æµ‹è¯•...")
            obs, info = env.reset()
            obs = obs['measurements']
            logger.info(f"åˆå§‹è§‚æµ‹ç±»å‹: {type(obs)}, å½¢çŠ¶/ç»“æ„: {get_obs_shape(obs)}")
            total_reward = 0.0
            done = False
            while not done:
                action = agent.select_action(obs)
                next_obs, reward, _, _, info = env.step(action)
                next_obs = next_obs['measurements']
                done = info['collision'] or info['off_route'] or info['TimeLimit.truncated']
                total_reward += reward

                # æ„é€  batchï¼ˆå•æ­¥ï¼‰
                batch = {
                    "obs": torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(device),
                    "action": torch.as_tensor(action, dtype=torch.float32).unsqueeze(0).to(device),
                    "reward": torch.as_tensor([reward], dtype=torch.float32).to(device),
                    "next_obs": torch.as_tensor(next_obs, dtype=torch.float32).unsqueeze(0).to(device),
                    "done": torch.as_tensor([done], dtype=torch.bool).to(device),
                }

                metrics = agent.update(batch)
                obs = next_obs

                global_step+=1
                # æ‰“å°å…³é”®ä¿¡æ¯
                if global_step % train_config["log_interval"] == 0:
                    logger.info(f"  Step {global_step}: reward={reward:.3f}, total={total_reward:.2f}")
                    if 'speed' in info:
                        logger.info(f"    é€Ÿåº¦: {info['speed']:.2f} km/h")
                    # è®°å½•æ—¥å¿—
                    history.append(metrics)

                # å¯é€‰ï¼šä¿å­˜å›¾åƒï¼ˆè°ƒè¯•ç”¨ï¼‰
                # save_image(obs, now_step)

                if done:
                    logger.info(f"  â¹ï¸  Episode ç»“æŸ (info={info})")
                    break
            episode += 1

            logger.info(f"âœ… ç¬¬ {episode} è½®å®Œæˆï¼Œæ€»å¥–åŠ±: {total_reward:.2f}")

            # ä¿å­˜æ¨¡å‹
            if episode % train_config["save_freq"] == 0:
                logger.info(f"å¼€å§‹ä¿å­˜æ¨¡å‹ï¼š  Step {global_step}: reward={reward:.3f}, total={total_reward:.2f}")
                agent.save(rl_config,global_step,episode,env_config['world']['map'])

    except Exception as e:
        logger.error(f"âŒ ç¯å¢ƒè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    finally:
        logger.info("\nğŸ§¹ æ­£åœ¨å…³é—­ç¯å¢ƒ...")
        env.close()
        logger.info("ğŸ‘‹ æµ‹è¯•ç»“æŸã€‚")


def get_obs_shape(obs):
    """è¾…åŠ©å‡½æ•°ï¼šé€’å½’æ‰“å°è§‚æµ‹ç»“æ„"""
    if isinstance(obs, dict):
        return {k: get_obs_shape(v) for k, v in obs.items()}
    elif isinstance(obs, np.ndarray):
        return obs.shape
    else:
        return type(obs)


if __name__ == "__main__":
    main()
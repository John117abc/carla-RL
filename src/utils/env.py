import random
import numpy as np
import torch
import warnings
from pathlib import Path

def setup_code_environment(config):
    """
    è®¾ç½®è®­ç»ƒç¯å¢ƒï¼Œç¡®ä¿å¯å¤ç°æ€§å’Œç¨³å®šæ€§ã€‚

    Args:
        config: é…ç½®å¯¹è±¡ï¼Œéœ€åŒ…å«ä»¥ä¸‹å­—æ®µï¼ˆç¤ºä¾‹ï¼‰ï¼š
            - seed: int
            - device: str ("cpu" or "cuda")
            - cudnn_deterministic: bool (å¯é€‰)
            - cudnn_benchmark: bool (å¯é€‰)
            - output_dir: str (å¯é€‰ï¼Œç”¨äºåˆ›å»ºç›®å½•)
    """
    # 1. è®¾ç½®éšæœºç§å­
    seed = getattr(config, 'seed', 22)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # æ‰€æœ‰ GPU
    np.random.seed(seed)
    random.seed(seed)

    # 2. CuDNN è®¾ç½®
    cudnn_deterministic = getattr(config, 'cudnn_deterministic', True)
    cudnn_benchmark = getattr(config, 'cudnn_benchmark', False)

    torch.backends.cudnn.deterministic = cudnn_deterministic
    torch.backends.cudnn.benchmark = cudnn_benchmark

    if cudnn_deterministic:
        print("âš ï¸  CUDNN deterministic enabled â€” may slow down training.")
    if cudnn_benchmark:
        print("âš¡ CUDNN benchmark enabled â€” faster but non-deterministic.")

    # 3. è®¾å¤‡æ£€æŸ¥
    device_str = getattr(config, 'device', 'cuda')
    if device_str == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸  CUDA not available, falling back to CPU.")
        config.device = 'cpu'
    else:
        config.device = device_str

    # 4. åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰ï¼‰
    output_dir = getattr(config, 'output_dir', None)
    if output_dir:
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ Output directory: {output_dir}")

    # 5. æŠ‘åˆ¶çƒ¦äººçš„è­¦å‘Š
    warnings.filterwarnings("ignore", category=UserWarning, module="torch")
    warnings.filterwarnings("ignore", category=FutureWarning)

    print(f"âœ… Environment set up. Seed={seed}, Device={config.device}")